{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABALONE CASE STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libreries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all neccessory Libreries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset\n",
    "\n",
    "df= pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/dataset1/master/abalone.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset and see all columns with first five rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of data with number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4177 Rows and 9 Columns in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the detailed description of all the rows and columns like count, mean value, standard deviation, minimum and maximum values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatypes of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data types of all the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have object(string) datatype in sex column which are catogorical values. Integer data type in rings columns. and rest are floating values, all are independent variable accept Rings. Rings is a target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking is there any null value in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check is there any null value present in any column\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing value in whole dataset.\n",
    "As we see no null values present, now it's safe to preceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the complete information about data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Rings\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Rings']== \" \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there are no missing or spaces are available in target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As mentioned in the problem statement, need to add +1.5 on each value of target variable convert it into regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 1.5 to each value of rings column\n",
    "Rings = [] #empty list\n",
    "\n",
    "for i in df[\"Rings\"]:\n",
    "    a=i+1.5\n",
    "    Rings.append(a)\n",
    "    \n",
    "Rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Rings\"]= Rings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after adding 1.5 in target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization (Uni Variate analysis)\n",
    "Uni variate analysis works with only one variable, hence it is called uni variate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Length\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see length is almost normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Diameter\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small amount of skewness present in Diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Height\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Height contains soo much skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Whole weight\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole Weight variable is also skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Shucked weight\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shucked weight is contains skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Viscera weight\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viscera weight has the skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Shell weight\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shell weight is also have the skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(df[\"Rings\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis through boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = df[[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\", \"Viscera weight\", \"Shell weight\", \"Rings\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship Visualizing\n",
    "\n",
    "plt.figure(figsize = (25,20), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in fe:\n",
    "    if plotnumber <= 9: # as we see there are eight columns in the data\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sn.boxplot(fe[column], color = 'c')\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        \n",
    "    plotnumber += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Every column contains outliers(\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\", \"Viscera weight\", \"Shell weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi variate analysis\n",
    "Bi variate analysis is works with two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship Visualizing\n",
    "\n",
    "plt.figure(figsize = (35,35), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in df:\n",
    "    if plotnumber <= 15:\n",
    "        ax = plt.subplot(5,3,plotnumber)\n",
    "        plt.scatter(df[column],df['Rings'], color='g')\n",
    "        plt.xlabel(column,fontsize=26)\n",
    "        plt.ylabel('Rings', fontsize=26)\n",
    "    plotnumber += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some variables are having some amount of linear relationship with target variable\n",
    "and some are having  non linear relationship with target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in the plot some outliers are also present in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Variate analysis\n",
    "Multi variate analysis find the relationship with all variables.\n",
    "Now we will visualize the data and check the coiefficient of multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cor = df.corr().abs()\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "sn.heatmap(df_cor, vmin=-1, vmax= 1, annot=True, square=True,\n",
    "          center=0, fmt='.1g', linewidths=.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in plot 'Shucked weight' and 'Rings' correlation value is in less amount(40%).\n",
    "'Shell weight' and 'Whole weight' are strongly correlated with 100%.\n",
    "'Viscera weight' and 'Whole weight' are strongly correlated with 100%.\n",
    "'Shucked weight' and 'Whole weight' are strongly correlated with 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find out which columns are positively and negatively correlated with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,7))\n",
    "df.corr()['Rings'].sort_values(ascending = False).drop(['Rings']).plot(kind = 'bar', color = 'g')\n",
    "plt.xlabel('Feature', fontsize = 15)\n",
    "plt.ylabel('Rings', fontsize = 15)\n",
    "plt.title('correlation', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in plot all features are positively correlate with target variable. There are no negative correlation in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After visualization conclude that all input variables are having some/good amount relationship with target variable. Now proceed futher for next steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "#### Encode input variable 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 unique values present in sex column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of count of each unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].dtypes==\"object\":\n",
    "        df[i]=enc.fit_transform(df[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers \n",
    "Now we found the outliers and skewness in some variables.Removing outliers first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Outlier removal using Zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Zscore technique taking standard deviation 3\n",
    "#for Zscore outlier removal technique import library from scipy\n",
    "\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_score= zscore(df[['Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight', 'Shell weight']])\n",
    "abs_z_score = np.abs(z_score)\n",
    "\n",
    "filtering_entry = (abs_z_score < 3).all(axis = 1)\n",
    "\n",
    "new_df = df[filtering_entry]\n",
    "\n",
    "print(\"shape before and after\")\n",
    "print(\"shape before\".ljust(20),\":\", df.shape)\n",
    "print(\"shape after\".ljust(20),\":\", new_df.shape)\n",
    "print(\"Percentage Loss\".ljust(20),\":\", (df.shape[0]-new_df.shape[0])/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.226% data will loss after applying Zscore technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97.773% data remains after using Zscore outlier technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Outlier Removing using IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from boxplot in EDA, we came to know that outliers present in following columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data again to check outliers are present at low side or high side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features in which outliers are detected\n",
    "fe = df2[[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\", \"Viscera weight\", \"Shell weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,20))\n",
    "graph = 1\n",
    "\n",
    "for column in fe:\n",
    "    if graph <= 30:\n",
    "        ax = plt.subplot(4,2, graph)\n",
    "        sn.boxplot(fe[column], color = 'c')\n",
    "        plt.xlabel(column, fontsize = 20)\n",
    "        \n",
    "    graph+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the IQR (Inter Quantile Range) to identify outliers\n",
    "#formula for finding IQR\n",
    "\n",
    "#1st quantile 25%\n",
    "q1 = df2.quantile(0.25)\n",
    "\n",
    "#3rd quantile 75%\n",
    "q3 = df2.quantile(0.75)\n",
    "\n",
    "#IQR = Inter Quantile Range\n",
    "iqr = q3-q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection formula "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher side ==> Q3 + (1.5 * IQR)\n",
    "#### Lower side ==> Q1 - (1.5 * IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outliers removal from higher side "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the Outliers for Length\n",
    "#Remove outliers from lower side so, use lower side formula\n",
    "\n",
    "Length_out = (q1.Length - (1.5*(iqr.Length)))\n",
    "Length_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = np.where(df2['Length'] < Length_out)\n",
    "df2 = df2.drop(df2.index[index_out])\n",
    "df2.shape\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing outliers the 4128 rows will remains in dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diameter is having outliers in lower side so use lower side formula\n",
    "#Check the Outliers for Diameter\n",
    "#Remove outliers from lower side so, use lower side formula\n",
    "\n",
    "Diameter_out = (q1.Diameter - (1.5*(iqr.Diameter)))\n",
    "Diameter_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = np.where(df['Diameter'] < Diameter_out)\n",
    "df2 = df2.drop(df2.index[index_out])\n",
    "df2.shape\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing outliers the 4069 rows will remains in dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height is having outliers in lower side so use lower side formula\n",
    "#Check the Outliers for Height\n",
    "#Remove outliers from lower side so, use lower side formula\n",
    "\n",
    "Height_out = (q1.Height - (1.5*(iqr.Height)))\n",
    "Height_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = np.where(df2['Height'] < Height_out)\n",
    "df2 = df2.drop(df2.index[index_out])\n",
    "df2.shape\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as shown in boxplot we have outlier in higher side of height also\n",
    "#Remove outliers from higher side so, use higher side formula\n",
    "\n",
    "Height_out = (q3.Height + (1.5*(iqr.Height)))\n",
    "Height_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = np.where(df2['Height'] > Height_out)\n",
    "df2 = df2.drop(df2.index[index_out])\n",
    "df2.shape\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing outliers the 4060 rows will remains in dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as shown in boxplot we have outlier in higher side of whole weightafter removing outliers the 4069 rows will remains in dataframe. \n",
    "#Remove outliers from higher side so, use higher side formula\n",
    "\n",
    "Wholeweight_out = (1.153000 + (1.5*(1.153000-0.441500)))\n",
    "Wholeweight_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = np.where(df['Whole weight'] > Wholeweight_out)\n",
    "df2 = df2.drop(df2.index[index_out])\n",
    "df2.shape\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing outliers in Whole weight the 4030 rows will remains in dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as shown in boxplot we have outlier in higher side of Shucked weight \n",
    "#Remove outliers from higher side so, use higher side formula\n",
    "\n",
    "Shuckedweight_out = (0.253000 + (1.5*(0.253000-0.186000)))\n",
    "Shuckedweight_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Shucked weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = np.where(df2['Shucked weight'] > Shuckedweight_out)\n",
    "df2 = df2.drop(df2.index[index_out])\n",
    "df2.shape\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing outliers in Shucked weight the 2101 rows will remains in dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as shown in boxplot we have outlier in higher side of Viscera weight \n",
    "#Remove outliers from higher side so, use higher side formula\n",
    "\n",
    "Visceraweight_out = (0.502000 + (1.5*(0.502000-0.093500)))\n",
    "Visceraweight_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = np.where(df['Viscera weight'] > Visceraweight_out)\n",
    "df2 = df2.drop(df2.index[index_out])\n",
    "df2.shape\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing outliers in Viscera weight the 2101 rows will remains in dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After removing outliers using IQR technique there are 2101 rows will remains in dataset.\n",
    "Now, find how much data loss in IQR method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49.70 % data loss after using IQR technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50.30% data remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying Zscore and IQR technique to remove outliers. We conclude that less amount data will loss in Zscore technique so we will go with Zscore technique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the skewness and remove that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there are some variables are skewed, whoes value is not lies between -0.5 to +0.5 this range.\n",
    "\n",
    "Length,\n",
    "Diameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outliers datatype. If data types of skewed column is integer (catogorical) than no need to remove skewness from that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Power transformation to remove skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In power transformation we will take the mean value in place of 0th value skewed data and convert that into normal data(distribution)/less skewed data and ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying Power transformation on skewed columns\n",
    "\n",
    "new_df['Length'] = new_df['Length'].replace(0,new_df['Length'].mean())\n",
    "new_df['Diameter'] = new_df['Diameter'].replace(0,new_df['Diameter'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(new_df[\"Length\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(new_df[\"Diameter\"], color = 'g')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in plot skewness removes after using power transformation skewness removes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the columns into featuers and target:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X= features, y=Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df.drop(columns = 'Rings', axis=1)\n",
    "y = new_df['Rings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_scalar = ss.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variables are scaled now using standard scaler technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance inflation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"vif\"] = [variance_inflation_factor(x_scalar, i) for i in range(x_scalar.shape[1])]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "#lets check the values\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we have saw in the table vif value is greater than 5 for many columns, so drop maximum value column to avoid multiclinearity issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=new_df.drop(['Whole weight'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df.drop(columns = 'Rings', axis=1)\n",
    "y = new_df['Rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_scalar = ss.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"vif\"] = [variance_inflation_factor(x_scalar, i) for i in range(x_scalar.shape[1])]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "#lets check the values\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best random state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "for i in range(1,200):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.30, random_state=i)\n",
    "    mod= DecisionTreeRegressor()\n",
    "    mod.fit(x_train, y_train)\n",
    "    pred = mod.predict(x_test)\n",
    "    acc=r2_score(y_test, pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "print(\"Best accuracy is \",maxAccu, \"on Random_state \", maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_scalar, y, test_size=0.2, random_state = 81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "Lr=LinearRegression()\n",
    "Lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=Lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation of Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score= cross_val_score(Lr, x, y, cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters = {'alpha' :[.0001, .001, .01, .1, 1, 10], 'random_state':list(range(0,10))}\n",
    "ls = Lasso()\n",
    "clf = GridSearchCV(ls, parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = Lasso(alpha = 0.01, random_state=0)\n",
    "ls.fit(x_train, y_train)\n",
    "ls.score(x_train, y_train)\n",
    "pred_ls = ls.predict(x_test)\n",
    "\n",
    "laso = r2_score(y_test, pred_ls)\n",
    "laso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score= cross_val_score(ls, x, y, cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The r2 score for linear regression model is : 52.50%\n",
    "###### Cross validation score for linear regression is : 35.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Random Forest Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "parameters ={'criterion':['mse', 'mae'], 'max_features':[\"auto\",\"sqrt\",\"log2\"]}\n",
    "Rfr= RandomForestRegressor()\n",
    "clf =GridSearchCV(Rfr, parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rfr =RandomForestRegressor(criterion = \"mse\", max_features=\"log2\")\n",
    "Rfr.fit(x_train, y_train)\n",
    "Rfr.score(x_train, y_train)\n",
    "pred_decision = Rfr.predict(x_test)\n",
    "\n",
    "Rfrs = r2_score(y_test,pred_decision)\n",
    "print('R2 Score: ',Rfrs*100)\n",
    "\n",
    "Rfrscore = cross_val_score(Rfr, x, y, cv=3)\n",
    "Rfrc = Rfrscore.mean()\n",
    "print('Cross Val Score: ',Rfrc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The r2 score for Random Forest Regressor model is : 53.07%\n",
    "###### Cross validation score for Random Forest Regressor is : 50.07%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "dtree = DecisionTreeRegressor()\n",
    "dtree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dtree = dtree.predict(x_test)\n",
    "print(r2_score(y_test,pred_dtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score= cross_val_score(dtree, x, y, cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The r2 score for Decision tree regression model is : 14.02%\n",
    "###### Cross validation score for Decision tree regression is : 25.57% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svr = svr.predict(x_test)\n",
    "print(r2_score(y_test,pred_svr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score= cross_val_score(svr, x, y, cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The r2 score for  SVR model is : 51.19%\n",
    "###### Cross validation score for SVR is : 40.87% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffrence between r2 score and cross validation score of linear regression model is : 17.24%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffrence between r2 score and cross validation score Random Forest Regressor model is : 3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffrence between r2 score and cross validation score of Decision Tree Regressor model is : 11.55%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffrence between r2 score and cross validation score of SVR model is : 10.32%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, best model is Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest Classifier\n",
    "\n",
    "Parameters = {'n_estimators' : [200, 700],\n",
    "              'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "              'max_depth' : [4, 5, 6, 7, 8],\n",
    "              'criterion' : ['mse', 'mae']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV=GridSearchCV(RandomForestRegressor(),Parameters,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.best_params_ # printing the best parameters found by GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = RandomForestRegressor( criterion='mse', max_depth=7 , max_features='log2', n_estimators=700)\n",
    "\n",
    "mod.fit(x_train, y_train)\n",
    "pred =mod.predict(x_test)\n",
    "print(r2_score(y_test, pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating binary file first\n",
    "\n",
    "with open(\"model_pickle\", \"wb\") as f:\n",
    "    pickle.dump(rfr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading Bbinary file\n",
    "\n",
    "with open(\"model_pickle\",\"rb\") as f:\n",
    "    mp=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
